---
title: Protestantische Arbeitsethik (1)
author: Simon Büttner
date: '2020-09-25'
slug: protestantische-arbeitsethik
categories: []
tags: []
keywords: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
library(psych)
library(lavaan)
library(mirt)
library(dplyr)
load("../../static/data/ProtestandWorkEthic/PWES.Rdata")
```
# Protestantische Arbeitsethik
Mein erster Post soll Einblick darin geben, wie ein Psychologe grundsätzlich versucht, bestimmte psychologische Konstrukte/Eigenschaften, die er sich ausgedacht hat, empirisch zu untersuchen. 
Den eigentlich sehr spannenden Prozess der Itemgenerierung lassen wir hier außen vor und steigen bei der empirischen Überprüfung der Items ein.
**Items sind die einzelnen Aufgaben, die man in einem Test bearbeitet.**
Bei Persönlichkeitstests sind es Aussagen wie "Ich lese gerne Blogs", die man z.B. von 1-5 danach bewerten soll, inwiefern man ihnen zustimmt.
Bei solchen Einschätzungen von 1-5 spricht man dann von Likert-Skalen bzw. einem Likert-Skalen Item.
Bei Leistungstests wäre ein Item z.B. eine Rechenaufgabe im offenen oder Multiple-Choice Format.

Den empirischen Teil der Fragebogenkonstruktion möchte ich dabei anhand der etwas ungewöhnlichen "Protestant Work Ethic Scale" bestehend aus 19 Likert-Skalen Items untersuchen.
Die dazugehörigen Daten sind auf [Open Psychometrics](https://openpsychometrics.org/_rawdata/) frei abrufbar. 
Wieso ausgerechnet so eine Randerscheinung psychologischer Konstrukte?
Mein Interesse rührt daher, dass nach Maßen der allgemeinen Intelligenz vor allem die Persönlichkeitskonstrukte Integrität und Gewissenhaftigkeit Prädiktoren des Berufserfolgs, aber auch weiter angelegter Maße eines "gelungenen Lebens" sind.
Grundsätzlich würde ich (auch nach Sichtung der Items der PWES) das damit erfasste Konstrukt in der Nähe von Gewissenhaftigkeit und Integrität ansiedeln.
Erstaunlich fand ich eigentlich immer, dass diese Konstrukte klassischer (Sekundär-)Tugenden so bedeutsam sind, haben diese heutzutage doch irgendwie an Ansehen verloren - werden im schlimmsten Fall sogar auch in die Nähe der "autoritären Persönlichkeit" gestellt werden, wodurch sie beinahe etwas Schmuddeliges an sich hängen haben.

In Deutschland haben diese Eigenschaften und das Verhältnis zu ihnen eine gewisse Sonderstellung, da es sich vor allem um "preußische Tugenden" (Pünktlichkeit, Arbeitsamkeit, Pflichtbewusstsein, Fleiß) handelt.
Heutzutage rühmt man sich besonders hier im Ländle dieser Tugenden (im Besonderen der Sparsamkeit), was sich nicht nur aber auch über die religiöse Geschichte ein Stück weit erklären lassen könnte: In Preußen wie in Schwaben (sind und) waren große Teile der Bevölkerung Protestanten. 
Diese Verwandtschaft findet schönen Ausdruck in den historischen Begebenheiten, dass der Schwabe Hegel im preußischen Berlin lehrte oder dass die "schwäbischen" Hohenzollern die preußischen Könige stellten.


Ich hatte mich deswegen schon einige Zeit gefragt, wieso noch niemand auf die Idee gekommen ist, eine Art "Schwäbische Hausfrauenskala" oder etwas leichter von der Zunge gehenden "Ländleskala" zu entwickeln. 
Solange sich niemand dieses Unternehmens annimmt, muss eben auf die "Protestant Work Ethic Scale" (PWES) zurückgegriffen werden.
Diese Skala geht zurück auf Max Webers Werk "Die protestantische Ethik und der Geist des Kapitalismus", in dem Weber die These verfolgt, der asketisch angelegte in Nordeuropa (und mit Nordeuropa assoziierte Nationen) verbreitete Protestantismus (im Besonderen der Calvinismus) sei als eine Triebkraft hinter der Entstehung des (Geist des) Kapitalismus zu verstehen.

## Aber zunächst, wie sehen die PWES Items aus?

* Q1	Most people spend too much time in unprofitable amusements. 
* Q2	Our society would have fewer problems if people had less leisure time. 
* Q3	Money acquired easily (e.g. through gambling or speculation) is usually spent unwisely. 
* Q4	There are few satisfactions equal to the realization that one has done one's best at a job. 
* Q5	The most difficult college courses usually turn out to be the most rewarding. 
* Q6	Most people who don’t succeed in life are just plain lazy. 
* [Q7	The self-made person is likely to be more ethical than someone who is born to wealth.]
* Q8	I often feel I would be more successful if I sacrificed certain pleasures. 
* Q9__Rekodiert	People should have more leisure time to spend in relaxation.  
* Q10	Anyone who is able and willing to work hard has a good chance of succeeding. 
* Q11	People who fail at a job have usually not tried hard enough. 
* Q12	Life would have very little meaning if we never had to suffer. 
* Q13__Rekodiert	Hard work offers little guarantee of success. 
* [Q14	The credit card is a ticket to careless spending.]
* Q15__Rekodiert	Life would be more meaningful if we had more leisure time. 
* Q16	The person who can approach an unpleasant task with enthusiasm is the one who gets ahead. 
* Q17	If one works hard enough they are likely to make a good life for themselves. 
* Q18	I feel uneasy when there is little work for me to do. 
* Q19	A distaste for hard work usually reflects a weakness of character.

Wie man sieht, verkörpert diese Skala unsere (Groß-)Eltern, die erhobenen Zeigefinders mahnen, unsere Zeit nicht zu verschwenden, mehr Geld zu sparen, und stets hart zu arbeiten.
Was man außerdem erkennen kann, ist dass jeglicher Bezug zur Prädestinationslehre des Calvinismus fehlt. 
Ein solcher Bezug wäre sicher unheimlich spannend, denn psychologisch kann der calvinistische Glaube an Prädestination mit interqessanten Effekten einhergehen.
Zum einen sucht man als Gläubiger durch weltlichen Erfolg zu bestätigen, dass man von Gott auserwählt ist und zum anderen kann der Glaube, auserwählt zu sein, ungeheurlich das Selbstvertrauen steigern. 
Nicht zu unrecht konzentriert sich Weber deshalb auf den Calvinismus. 
Interessant wäre die Wirkung von Prädestinationsüberzeugungen deshalb alle Mal, auch wenn diese gar nicht in der Skala aufgenommen wurden, was aber auch verständlich ist, ist die Skala doch eine "Arbeitsethik"-Skala.

Bevor ich zu den weiteren Analysen komme, möchte ich vorwegnehmen, dass die Items Q7 und Q14 nicht recht zu funktionieren scheinen, egal was ich mir in den Daten angeschaut habe.
Grund genug, diese Items auszuschließen. 

<!-- In Bezug auf die Skala hat das auch schon Bedeutung für uns: die schnell gezückte (goldene) Kreditkarte scheint für die vorliegenden Testpersonen wenig mit eine eher asketisch angeregten Ethik zu tun zu haben. -->
<!-- Ich schätze, dass die Autoren dieser Skala vor allem darauf hinauswollten, dass mancher Personen Konsumwünsche größer als ihre Geldbeutel sind, sodass diese auf Pump erfüllt werden statt auf ein gefülltes Sparschwein zu warten (ich habe noch nicht geschaut, von wann diese Daten überhaupt sind; vorstellbar ist, dass sich die Nutzung von Kreditkarten doch heute deutlich davon unterscheidet, wie diese noch 1970 eingesetzt wurden - dann ist das Item einfach aus der Zeit gefallen). -->
<!-- Jedenfalls scheinen diese Items diese Einstellung entweder nicht recht zu erfassen oder aber die Einstellung ist einfach unabhängig vom zugrundeliegenden latenten Konstrukt. -->

<!-- Item Q7 scheint meinem Gefühl nach darauf abzuzielen, die Einstellung Reichgeborene seien tendenziell dekadent oder verdienten zumindest ihren Reichtum nicht so sehr wie ein Self-Made-(Wo)Man.  -->
<!-- In gewisser Weise macht es deshalb meiner Meinung nach Sinn, dass diese relativ spezielle Meinung über Reiche nicht zum allgemeinen PWES Konstrukt passt (wie dieses zu verstehen ist, kann unten erst wirklich untersucht werden). -->

# Grundlegende Faktorenstruktur: fa.parallel()
G'nug g'schwätzt.
**Um die Frage zu beantworten, welche Faktorstruktur der PWES zugrundeliegt, ist zunächst zu klären, wie viele Faktoren/Dimensionen sich hinter den Daten verbergen. Aber was bedeutet das eigentlich?** Wenn Psychologen einen Test konstruieren, untersuchen sie in der Regel, inwiefern einzelne Items des Tests miteinander zusammenhängen. 
Bei uns: Stimmt jemand, der der Aussage "Wenn man hart genug arbeitet, wird das eigene Leben mit höherer Wahrscheinlicheit besser" (Q17) zustimmt, auch der Aussage zu "Jeder der fähig und willens ist, hart zu arbeiten, hat eine gute Chance erfolgreich zu sein" (Q10).
Und wenn ja, welchen Aussagen stimmt er dann noch zu?
Ziel ist dann, aus den einzelnen Antworten eine aggregierte Information zu erhalten. 
Also statt zu sagen, Person A stimmt Items 1, 2, 3 etc. zu, zu sagen Person A ist davon überzeugt, dass harte Arbeit zu Erfolg führt.
Auf diese Weise wird eine (statistische) Dimension / ein Faktor dann zu einem psychologischen Konstrukt, einer Persönlichkeitseigenschaft oder -fähigkeit oder einem latenten Trait - um nur einige Benennungen aufzuführen.
Diese übergeordneten Eigenschaften mit einem Test zu erfassen, ist das Ziel der (meisten) Testentwickler. 
Wichtig ist dabei, dass die einzelnen Items hoch mit dieser statistisch konstruierten Dimension zusammenhängen (und im einfachsten Fall sehr wenig mit anderen Dimensionen), man sagt "hoch auf der Dimension lädt".
Da das mit den Items Q7 und Q14 nicht recht geklappt hat, sind diese rausgeflogen.

Hat man dann eine Zuordnung von Items zu den Dimensionen gefunden, berechnet man in irgendeiner Weise (zumeist ein einfacher Summenscore über die Items hinweg) auf Basis genau dieser Items z.B. inwiefern eine Person der Überzeugung ist, dass harte Arbeit erfolgreich macht.
Hierfür bedient man sich vergleichsweise einfacher linearer Algebra, um die Struktur hinter den gegebenen Antworten auf die vielen Items zu untersuchen.
**Über eine Hauptkomponenten- oder Faktorenanalyse kann man wie beschrieben Dimensionen aus ganz vielen verschiedenen gegebenen Antworten extrahieren.**
Das sind keine psychologenspezifische Methoden, sondern vergleichsweise weit verbreitete Methoden.
So findet zum Beispiel die Hauptkomponentenanalyse auch im Machine Learning Einsatz, ebenfalls um aus vielen gegebenen Daten die wirklich vorhandene Struktur zu extrahieren, einen Datenwust also grundsätzlich zu vereinfachen.

Das erste Problem besteht dann darin, zu entscheiden, wie viel Struktur tatsächlich hinter den Daten steht, also wie viele psychologische Dimensionen wir finden können.
Klassischerweise wird hierfür ein Screeplot genutzt, der die Eigenwerte extrahierter Hauptkomponenten/Faktoren (das sind quasi die übergeordneten Dimensionen, die wir suchen) danach sortiert, wie viel Rauschen bzw. Varianz in den Daten sie erklären.
Außerdem werden mit der hier verwendet fa.parallel Funktion zufällig Daten simuliert, die unseren Daten ähneln, aber keine der dahinterliegenden Struktur enthält. 
Auf diese Weise können wir dann entscheiden, was echte Struktur in den Daten ist und was nur zufälliges Rauschen ist.
Man sieht nun sehr schön, dass besonders ein Faktor / eine Hauptkomponente hinter den Daten steckt.
Allerdings ließen sich auch weitere Dimensionen finden, die nicht rein zufälliger Natur zu sein scheinen (vornehmlich anhand der Punkte über der unteren roten Linie zu sehen, oder am Output "Parallel analysis suggests that the number of factors =  4") - doch das wird dann vielleicht einmal ein eigener Eintrag.
Wir halten im Sinne des Tests die Sparsamkeit hoch und betrachten nur die eine Hauptdimension.


```{r}
set.seed(1234)
fa.parallel(dat)
```

# Das Graded Response Model der protestantischen Arbeitsethik: Model Fit
Um den Test jetzt genauer statistisch zu untersuchen, stülpen wir den Daten ein eindimensionales statistisches Modell über (was genau das macht sei hier zurückgestelt. Eine Google Suche ergibt diese netten Seiten:[allgemeine Erklärung](https://www.statisticshowto.com/graded-response-model-ordered-categorical/) sowie [eine detailliertere Erklärung](http://statmath.wu-wien.ac.at/~hatz/psychometrics/11w/GPCM_GRM_GRASOM.pdf). 
Ganz einfach gesagt modellieren wir, wie die Items beantwortet werden in Abhängigkeit der zugrundeliegenden Fähigkeitsausprägung.

```{r}
# gmodel1 <- mirt(dat, 1, "graded", TOL = .0001)
summary(gmodel1)
# (m2.gmodel1<-M2(gmodel1, type = "C2"))
m2.gmodel1 %>% round(.,3)
itemfit(gmodel1, fit_stats = "PV_Q1")
```
Über die hier verwendeten Funktionen können wir schon einige Aussagen treffen:
1. Die "summary"-Funktion zeigt uns: eindimensionales Modell erklärt immerhin 41% der Varianz in den Daten: "Proportion Var:  0.411")
2. Die "summary"-Funktion: alle Items laden hinreichend gut auf diesem Faktor: die Zahlen unter F1 geben die Faktoreladungen an ( = wie sehr hängt die Zustimmung  zu einem Item von der zugrundeliegenden Eigenschaft ab) sind mindestens bei .44 - ab .32 ist es "gut genug".
3. "M2" gibt uns einige CFA Fit Indizes, das sind Kennwerte, die uns erlauben einzuschätzen, wie gut unser Modell auf die Daten passt. Dabei zeigt sich: die Modell und Daten passen relativ gut aufeinander (RMSEA nahe 0.05, SRMSR kleiner .1, TLI nahe .9). Aber, aber: wir haben ja auch schon 2 Items ausgeschlossen. Und dennoch Raum nach oben ist auch hier noch.
4. "itemfit" zeigt uns, inwiefern die empirischen Antworten auf einzelne Items *nicht* modellkonform sind. Wünschenswert ist, dass "p.PV_Q1" größer als .05 oder .01 ist, dass also keine signifikante Modellabweichung bei einzelnen Items besteht. Das ist grundsätzlich der Fall.

# Messgenauigkeit
Jetzt schauen wir einmal in Richtung Benutzbarkeit der Skala.
Wir schauen uns hierfür die Reliabilität der Skala an und außerdem die Verteilung der (latenten) Faktorscores einzelner Personen, also deren Theta-Werte an.
**Die Relabilität gibt an, wie genau wir messen können, welche Ausprägung eine Person auf einer psychologischen Dimension erreicht.**
Sie kann zwischen 0 (keine Messgenauigkeit) und 1 liegen (perfekte Messgenauigkeit).
Ab .7 ist die Genauigkeit grundsätzlich in Ordnung, bei .8 werden wir langsam glücklich und (viel) mehr als .9 sollten wir nicht erwarten.

Innerhalb der IRT gibt es nun eigentlich keinen einen natürlichen Wert, um die Messgenauigkeit eines Tests unabhängig der Personenfähigkeit angibt. 
Stattdessen liefert jedes einzelne Item für unterschiedliche Personenfähigkeiten unterschiedlich viel Information (hierbei können wir die statistische [Fischer-]Information relativ unproblematisch als alltagssprachliche Information auffassen).
Manche Items helfen uns also sehr gut im oberen Bereich zu differenzieren, umgekehrt aber im unteren Bereich nicht so sehr; oder auch anders herum. 
Grundsätzlich ist diese Auffassung der Messgenauigkeit sehr intuitiv. 
Wir stellen uns vor, wir möchten die Mathematikfähigkeit von Gymnasiasten in Erfahrung bringen.
Dazu stellen wir ihnen die Frage "Was ergibt 2+2?". 
Wahrscheinlich (und hoffentlich) wird jeder diese Frage korrekt beantworten, denn sie ist viel zu einfach für diese Zielgruppe.
Wir haben dann keine Grundlage um einem Schüler zu attestieren, er sei mehr oder weniger mathebegabt als ein anderer.
Die Beantwortung von 2+2 liefert uns also keine Information.
Schön ist nun, dass diese plausible Annahme innerhalb der IRT ebenfalls gilt.
Unschön ist, dass man nicht direkt einen Wert anschauen kann, um die Messgenauigkeit des Tests zu beurteilen.
Aber es gibt auch innerhalb der IRT Abhilfe, indem man sich die marginale (oder empirische) Reliabilität anschaut ([hier gut erklärt](https://stats.stackexchange.com/questions/427631/difference-between-empirical-and-marginal-reliability-of-an-irt-model), sogar im Kontext des R Pakets, das ich hauptsächlich verwende. Grundsätzlich wird die Messgenauigkeit an den einzelnen Ausprägungen der Fähigkeit ins Verhältnis gesetzt zur allgemeinen Streuung der Fähigkeit), die man "ganz normal" wie andere Reliabilitäten interpretieren kann.

```{r}
marginal_rxx(gmodel1)
plot(gmodel1, type = "rxx", theta_lim = c(-3,3) )
```

Die marginale Reliabilität liegt bei .9 (Output von "marginal_rxx"), ist also ziemlich zufriedenstellend.
Außerdem habe ich die Messgenauigkeit als Reliabilität (nicht direkt als Information, wie in der IRT üblich) in Abhängigkeit der Personenfähigkeit geplotted, was ein typisches Muster ergibt: im mittleren Bereich wird die höchste Messgenauigkeit erreicht, an den Rändern sinkt sie etwas.

```{r}
# thetgm1 <- fscores(gmodel1, full.scores.SE = TRUE, method = "EAP")

plot(density(thetgm1[,"F1"]), main = "Verteilung der resultierenden 'protestantischen Arbeitsethik'-Eigenschaft")
```


# Kurzzusammenfassung
Bisher lief alles schön glatt. Die Reliabilität ist in Ordnung, der Modellfit ist in Ordnung - wir haben eine schöne einzelne Dimension protestantischer Arbeitsethik.
Aber mehr leider auch nicht. 
Spannend wäre jetzt zu untersuchen, inwiefern die psychologische Dimension, die wir gefunden haben mit anderen Dimensionen zusammenhängt und letztlich noch viel mehr, ob sie auch mit anderen Ereignissen, als der Beantwortung irgendwelcher Fragebögen einhergeht.
Ob also beispielsweise Personen, die einen hohen Wert auf der PWES haben im echten Leben erfolgreich sind, viel arbeiten (work hard, play hardly) etc.
Leider ist uns die Untersuchung des Letzteren vergönnt, da wir hierzu keine Daten haben.
Eine Minivalidierung der PWES können wir dennoch in Angriff nehmen - aber erst im nächsten Post. 


