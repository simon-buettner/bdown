---
title: Protestantische Arbeitsethik 1
author: Simon Buettner
date: '2020-10-04'
slug: protestantische-arbeitsethik-1.en-us
categories: []
tags: []
keywords: []
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
library(psych)
library(lavaan)
library(mirt)
library(dplyr)
load("../../static/data/ProtestandWorkEthic/PWES.Rdata")
```
# Wie funktioniert eigentlich psychologische Testentwicklung? (1)
## Protestantische Arbeitsethik
Mein erster Post soll Einblick darin geben, wie ein Großteil der Psychologen grundsätzlich versucht, bestimmte ausgedachte psychologische Eigenschaften, empirisch mit halbwegs modernen Tests zu untersuchen. 
Den eigentlich sehr spannenden Prozess der Itemgenerierung lassen wir hier außen vor und steigen bei der empirischen Überprüfung der Items ein.
**Halt erstmal: Was sind Items? Items sind die einzelnen Aufgaben, die man in einem Test bearbeitet.**
Bei Persönlichkeitstests sind es Aussagen in einem Frabogen wie "Ich lese gerne Blogs", die man z.B. von 1-5 danach bewerten soll, inwiefern man ihnen zustimmt.
Bei solchen Einschätzungen von 1-5 spricht man dann von Likert-Skalen bzw. einem Likert-Skalen Item.
Bei Leistungstests wäre ein Item z.B. eine Rechenaufgabe im offenen oder Multiple-Choice Format.

Den empirischen Teil der Fragebogenkonstruktion/-analyse möchte ich dabei anhand der etwas ungewöhnlichen ["Protestant Work Ethic Scale (PWES)"](https://psycnet.apa.org/record/1971-09987-001) bestehend aus 19 Likert-Skalen Items untersuchen.
Die dazugehörigen Daten sind auf [Open Psychometrics](https://openpsychometrics.org/_rawdata/) frei abrufbar. 
Wer den Test einmal selbst machen und herausfinden möchte, wie vergleichsweise hoch oder niedrig seine protestantische Arbeitsethik-Überzeugungen ausfallen, kann das [hier](https://openpsychometrics.org/tests/PWE/) tun.

Wieso ausgerechnet so eine vermeintliche Randerscheinung psychologischer Konstrukte?
Mein Interesse rührt daher, dass nach Maßen der allgemeinen Intelligenz von Testseite her vor allem die Persönlichkeitskonstrukte [Integrität und Gewissenhaftigkeit als Prädiktoren des Berufserfolgs](https://psycnet.apa.org/doiLanding?doi=10.1037%2F0033-2909.124.2.262) gelten können.
Grundsätzlich würde ich nach Sichtung der Items der PWES das damit erfasste Konstrukt in der Nähe von Gewissenhaftigkeit und Integrität ansiedeln.
Erstaunlich fand ich eigentlich immer, dass diese Konstrukte klassischer (Sekundär-)Tugenden so bedeutsam sind, haben diese heutzutage doch irgendwie an Ansehen verloren - werden im schlimmsten Fall sogar auch in die Nähe der "autoritären Persönlichkeit" gestellt werden, wodurch sie beinahe etwas Schmuddeliges an sich hängen haben.
Gleichzeitig möchte ich gar nicht bestreiten, dass die Bedeutsamkeit dieser klassischen Tugenden auf mittlerweile doch recht alter Forschung basiert und heute ggf. ein Stück weit an Gültigkeit verloren haben könnte.
Vielleicht aber auch nur in manchen Berufen oder Branchen. 
Und dennoch: Auch im agilsten Projekt beim freshesten IT-Start-Up dürfte am Ende wichtig sein, was tatsächlich 'naus g'schafft wird. 
Fleiß, Gewissenhaftigkeit und ein grundsätzliches Maß an Ehrlichkeit werden deshalb auch weiterhin bedeutsam sein (eine schnelle Auffassungsgabe sowieso).


In Deutschland haben diese Eigenschaften und das Verhältnis zu ihnen eine gewisse Sonderstellung, da es sich vor allem um "preußische Tugenden" handelt (Pünktlichkeit, Arbeitsamkeit, Pflichtbewusstsein, Fleiß, Genügsamkeit, Redlichkeit, ...).
Heutzutage rühmt man sich besonders hier im Ländle dieser Tugenden (im Besonderen der Sparsamkeit), was sich nicht nur aber auch über die religiöse Geschichte ein Stück weit erklären lassen könnte: In Preußen wie in Schwaben sind und waren große Teile der Bevölkerung Protestanten. 
Diese Verwandtschaft findet schönen Ausdruck in den historischen Begebenheiten, dass der Schwabe Hegel im preußischen Berlin lehrte oder dass die "schwäbischen" Hohenzollern die preußischen Könige stellten.


Ich hatte mich deswegen schon während des Studiums gefragt, wieso noch niemand auf die Idee gekommen ist, eine Art "Schwaben-" oder "Ländleskala" zu entwickeln (besonders, da ich mit Tübingen doch im Herzen Baden-Württembergs studiert habe). 
Solange sich niemand dieses Unternehmens annimmt, muss man sich eben mit der "Protestant Work Ethic Scale" (PWES) be- und vergnügen.
Diese Skala geht zurück auf Max Webers Werk "Die protestantische Ethik und der Geist des Kapitalismus", in dem Weber die These verfolgt, der innerweltlich-asketisch angelegte in Nordeuropa und mit Nordeuropa assoziierten Kulturkreisen verbreitete Protestantismus (im Besonderen der Calvinismus) sei als eine Triebkraft hinter der Entstehung des (Geist des) Kapitalismus zu verstehen.

## Wie sehen die PWES Items aus?
1349 vornehmlich aus den USA stammende Personen haben auf Likert-Skalen von 1-5 eingeschätzt, inwiefern sie folgenden Aussagen/Items zustimmen:


* Q1	Most people spend too much time in unprofitable amusements. 
* Q2	Our society would have fewer problems if people had less leisure time. 
* Q3	Money acquired easily (e.g. through gambling or speculation) is usually spent unwisely. 
* Q4	There are few satisfactions equal to the realization that one has done one's best at a job. 
* Q5	The most difficult college courses usually turn out to be the most rewarding. 
* Q6	Most people who don't succeed in life are just plain lazy. 
* [Q7	The self-made person is likely to be more ethical than someone who is born to wealth.]
* Q8	I often feel I would be more successful if I sacrificed certain pleasures. 
* Q9__Rekodiert	People should have more leisure time to spend in relaxation.  
* Q10	Anyone who is able and willing to work hard has a good chance of succeeding. 
* Q11	People who fail at a job have usually not tried hard enough. 
* Q12	Life would have very little meaning if we never had to suffer.
* Q13__Rekodiert	Hard work offers little guarantee of success. 
* [Q14	The credit card is a ticket to careless spending.]
* Q15__Rekodiert	Life would be more meaningful if we had more leisure time. 
* Q16	The person who can approach an unpleasant task with enthusiasm is the one who gets ahead. 
* Q17	If one works hard enough they are likely to make a good life for themselves. 
* Q18	I feel uneasy when there is little work for me to do. 
* Q19	A distaste for hard work usually reflects a weakness of character.

Wie man sieht, erscheinen uns in dieser Skala unsere (Groß-)Eltern, die erhobenen Zeigefinders mahnen, unsere Zeit nicht zu verschwenden, mehr Geld zu sparen, und stets hart zu arbeiten, denn darauf kommt es an und diese Einstellung lohnt sich materiell wie spirituell.
Außerdem kann man erkennen, dass jeglicher Bezug zur für den Calvinismus bedeutsamen Prädestinationslehre fehlt.
Vereinfacht ist darunter zu verstehen, dass Gott von Anfang an erwählt hat, wer verdammt ist und wem die Gnade des ewigen Lebens zuteil wird.
Ein solcher Bezug wäre sicher unheimlich spannend, denn psychologisch könnten Prädestinationsüberzeugungen mit interessanten Effekten einhergehen.
Zum einen sucht man als Gläubiger durch weltlichen Erfolg zu bestätigen, dass man von Gott auserwählt ist und zum anderen kann der Glaube, auserwählt zu sein, ungeheuerlich das Selbstvertrauen steigern. 
Nicht zu unrecht konzentriert sich Weber deshalb auf den Calvinismus. 
Interessant wäre die Wirkung von Prädestinationsüberzeugungen deshalb alle Mal, auch wenn diese gar nicht in der Skala aufgenommen wurden, was aber auch verständlich ist, ist sie doch eine "Arbeitsethik"-Skala.

## Grundlegende Faktorenstruktur: Was steckt hinter den Daten?
G'nug g'schwätzt.
**Um die Frage zu beantworten, welche Faktorstruktur der PWES zugrunde liegt, ist für den gewieften Psychologen zunächst zu klären, wie viele Faktoren/Dimensionen sich hinter den Daten verbergen. Aber was bedeutet das jetzt?** 
Wenn Psychologen einen Test konstruieren, untersuchen sie in der Regel, inwiefern einzelne Items des Tests miteinander zusammenhängen bzw. auch nicht miteinander zusammenhängen. 
Bei uns: Stimmen jene, die der Aussage "Wenn man hart genug arbeitet, wird das eigene Leben mit höherer Wahrscheinlichkeit besser" (Q17) zustimmen, auch eher der Aussage zu "Jeder der fähig und willens ist, hart zu arbeiten, hat eine gute Chance erfolgreich zu sein" (Q10).
Und wenn ja, welchen Aussagen stimmen sie dann noch zu? 
Welche Aussagen werden unabhängig eines solchen Bündels an Aussagen beantwortet?
Ziel ist dann, aus den einzelnen Antworten eine aggregierte Information zu extrahieren. 
Also statt zu sagen, Person A stimmt Items 1, 2, 3 etc. zu, zu sagen Person A ist davon überzeugt, dass harte Arbeit zu Erfolg führt.


Auf diese Weise wird eine (statistische) Dimension / ein Faktor dann zu einem psychologischen Konstrukt, einer Persönlichkeitseigenschaft/-fähigkeit oder einem latenten Trait - um nur einige Benennungen aufzuführen, mit denen man im Endeffekt das gleiche bezeichnet.
Diese übergeordneten Eigenschaften mit einem Test zu erfassen, ist das Ziel der (meisten) Testentwickler. 
Wichtig ist dabei, dass die einzelnen Items hoch mit dieser statistisch konstruierten Dimension zusammenhängen (und im einfachsten Fall sehr wenig mit anderen Dimensionen), man sagt "hoch auf der Dimension / dem Faktor laden", da es sich um Faktorladungen handelt.
Da das mit den Items Q7 und Q14 nicht zufriedenstellend geklappt hat, sind diese rausgeflogen.
Hat man dann eine Zuordnung von Items zu den Dimensionen gefunden, berechnet man in irgendeiner Weise (zumeist ein einfacher Summenscore über die Items hinweg) auf Basis genau dieser Items z.B. inwiefern eine Person der Überzeugung ist, dass harte Arbeit erfolgreich macht.

Zur Untersuchung der Faktorstruktur bedient man sich (im Zweifel über Umwege) vergleichsweise einfacher linearer Algebra, um die Struktur hinter den gegebenen Antworten auf die vielen Items zu untersuchen.
**Über eine Hauptkomponenten- oder Faktorenanalyse kann man wie beschrieben Dimensionen aus ganz vielen verschiedenen gegebenen Antworten extrahieren.**
Sie unterscheiden sich zwar in der Theorie, aber im Endeffekt erlauben sie genau das, was Psychologen mit einem Test erreichen wollen: aus vielen Einzelinformationen eine theoretische Struktur anzunähern.  
Außerdem sind sie keine psychologiespezifischen Methoden, sondern vergleichsweise weit verbreitet.
So findet zum Beispiel die Hauptkomponentenanalyse auch im Machine Learning Einsatz, ebenfalls um einen Datenwust grundsätzlich zu vereinfachen.

Das erste Problem besteht nun darin, zu entscheiden, wie viel Struktur tatsächlich in den Daten steckt, also wie viele Dimensionen wir finden können.
Klassischerweise wird hierfür ein Screeplot genutzt, der die Eigenwerte extrahierter Hauptkomponenten/Faktoren - das sind quasi die übergeordneten Dimensionen, die wir suchen - danach sortiert, wie viel systematisches Rauschen bzw. Varianz in den Daten sie erklären.
Außerdem werden mit der hier verwendet 'fa.parallel' Funktion zufällig Daten simuliert, die unseren Daten ähneln, aber keine der dahinterliegenden Struktur enthalten. 
Auf diese Weise können wir dann entscheiden, was echte Struktur in den Daten und was nur zufälliges Rauschen ist.

Im Bild unten sieht man nun sehr schön, dass besonders ein Faktor / eine Hauptkomponente / Dimension in den Daten steckt.
Allerdings ließen sich auch weitere Dimensionen finden, die nicht rein zufälliger Natur zu sein scheinen (vornehmlich anhand der Punkte über der unteren roten Linie zu sehen, oder am Output "Parallel analysis suggests that the number of factors =  5") - doch wie man damit umgeht, wird dann vielleicht einmal ein eigener Blogpost.
Wir halten ganz im Sinne der PWES die Sparsamkeit hoch und betrachten nur diese eine Hauptdimension.


```{r}
set.seed(1234)
fa.parallel(dat)
```

## Das 'Graded Response Model' der protestantischen Arbeitsethik: einige Kennwerte
Um den Test jetzt eingehender zu untersuchen, stülpen wir den Daten ein eindimensionales statistisches Modell über: ein Graded Response Modell. 
Was genau das macht sei hier zurückgestellt. 
Eine Google Suche ergibt diese netten Seiten: [allgemeine Erklärung](https://www.statisticshowto.com/graded-response-model-ordered-categorical/) sowie [eine detailliertere Erklärung](http://statmath.wu-wien.ac.at/~hatz/psychometrics/11w/GPCM_GRM_GRASOM.pdf). 
Ganz einfach gesagt modellieren wir, wie die Items beantwortet werden in Abhängigkeit der zugrundeliegenden Fähigkeitsausprägung, also unserer sparsam gewählten Hauptdimension.
Damit gehen wir etwas über eine normale Faktorenanalyse hinaus, erreichen aber ein sehr ähnliches (aber besseres) Ziel als mit dieser.

```{r}
# gmodel1 <- mirt(dat, 1, "graded", TOL = .0001)
summary(gmodel1)
```
Über die hier verwendeten Funktionen können wir schon einige Aussagen treffen:

  1. Die **"summary"**-Funktion des Modells zeigt uns: das eindimensionale Modell erklärt immerhin 41% der Varianz in den Daten: "Proportion Var:  0.41")
  
  2. Die **"summary"**-Funktion zeigt weiter: alle Items laden hinreichend gut auf diesem Faktor: die Zahlen unter F1 geben die Faktorladungen an ( = wie sehr hängt die Zustimmung zu einem Item von der zugrundeliegenden Eigenschaft ab) sind absolut mindestens bei .398 -- ab .32 ist es "gut genug".


```{r}
# (m2.gmodel1<-M2(gmodel1, type = "C2"))
m2.gmodel1 %>% round(.,3)
itemfit(gmodel1, fit_stats = "PV_Q1")
```
  
  3. **"M2"** gibt uns einige CFA Fit Indizes aus. Das sind Kennwerte, die uns einzuschätzen erlauben, wie gut unser Modell insgesamt auf die Testdaten passt (oder andersherum). Dabei zeigt sich: Modell und Daten passen relativ gut aufeinander (RMSEA halbwegs nahe 0.05, SRMSR deutlich kleiner .1, TLI/CFI über .9). Aber, aber: wir haben ja auch schon 2 Items ausgeschlossen. Und dennoch Raum nach oben ist auch hier noch.
  
  4. **"itemfit"** zeigt uns, inwiefern die empirischen Antworten auf einzelne Items *nicht* modellkonform sind - quasi eine Betrachtung wie bei M2 aber auf Item- statt auf Testebene. Wünschenswert ist, dass "p.PV_Q1" größer als .05 oder .01 ist, dass also keine signifikante Modellabweichung bei einzelnen Items besteht. Mit Ausnahme von Q9A, Q13 und Q15 ist das grundsätzlich der Fall. 

## Messgenauigkeit: Reliabilität
Der erste Blick in die Daten der PWES ist schon recht vielversprechend (für die harte Analysearbeit scheinen wir belohnt zu werden), jetzt gehen wir einmal in Richtung Benutzbarkeit der Skala.
Wir schauen uns hierfür die Reliabilität der Skala an und außerdem die Verteilung der latenten Theta-Werte, also die PWES Dimension, die wir statistisch konstruiert haben.
**Die Reliabilität gibt an, wie genau wir messen können, welche Ausprägung eine Person auf einer psychologischen Dimension erreicht.**
Unsere psychologischen Messungen werden immer mit einer gewissen Ungenauigkeit behaftet sein.
Um aber valide Aussagen darüber zu treffen, ob eine Person sehr gewissenhaft ist oder nicht sowie um zu entscheiden, ob Person A gewissenhafter als Person B ist, sollte unsere Einschätzung über einer Einschätzung mittels Münzwurf liegen.
Die Reliabilität kann zwischen 0 (keine Messgenauigkeit, Münzwurf) und 1 liegen (perfekte Messgenauigkeit).
Ab .7 ist die Genauigkeit grundsätzlich in Ordnung, bei .8 werden wir langsam glücklich und (viel) mehr als .9 sollten wir nicht erwarten.

Innerhalb der [Item-Response-Theory (IRT; vereinfacht: eine psychologische Testtheorie)](https://en.wikipedia.org/wiki/Item_response_theory) gibt es nun eigentlich keinen solchen natürlichen Reliabilitäts-Wert, um die Messgenauigkeit eines Tests unabhängig der Personenfähigkeit anzugeben. 
Stattdessen liefert jedes einzelne Item für unterschiedliche Personenfähigkeiten unterschiedlich viel Information (hierbei können wir die statistische [Fischer-]Information relativ unproblematisch als alltagssprachliche Information auffassen).
Manche Items helfen uns also im oberen Dimensionsbereich genau zu messen, umgekehrt aber im unteren Bereich nicht so sehr; oder auch anders herum. 

Grundsätzlich ist diese Auffassung der Messgenauigkeit sehr intuitiv. 
Wir stellen uns vor, wir möchten die Mathematikfähigkeit von Abiturienten in Erfahrung bringen.
Dazu stellen wir ihnen die Frage "Was ergibt 2+2?". 
Wahrscheinlich (und hoffentlich) wird jeder diese Frage korrekt beantworten, denn sie ist viel zu einfach für diese Zielgruppe.
Wir haben dann keine Grundlage, einem Schüler zu attestieren, er sei mehr oder weniger mathebegabt als ein anderer.
Die Beantwortung von 2+2 liefert uns also keine Information, denn jeder kann sie richtig beantworten, in einem Test zur Erfassung der Mathefähigkeit von Abiturienten wäre diese Frage also Fehl am Platz.
Schön ist nun, dass diese plausible Betrachtungsweise innerhalb der IRT ebenfalls gilt.
Unschön ist, dass man deshalb nicht direkt einen Wert ausgeben kann, um die Messgenauigkeit eines Tests zu beurteilen.
Aber um den steil aufgebauten Spannungsbogen wieder etwas zu senken: man kann sich natürlich auch innerhalb der IRT Abhilfe verschaffen, indem man sich die marginale (oder empirische) Reliabilität anschaut, die man "ganz normal" wie andere Reliabilitäten interpretieren kann ([hier gut erklärt](https://stats.stackexchange.com/questions/427631/difference-between-empirical-and-marginal-reliability-of-an-irt-model), sogar im Kontext des R Pakets 'mirt', das ich hauptsächlich verwende. 
Grundsätzlich wird die Messgenauigkeit gemittelt über die einzelnen Fähigkeitsausprägungen ins Verhältnis gesetzt zur allgemeinen Streuung der Fähigkeit - das entspricht der Definition der Messgenauigkeit nach klassischer Testtheorie).

```{r}
marginal_rxx(gmodel1)
plot(gmodel1, type = "rxx", theta_lim = c(-3,3) )
```

Die marginale Reliabilität liegt bei .91 (Output von "marginal_rxx"), ist also ziemlich zufriedenstellend.
Außerdem habe ich die Messgenauigkeit als Reliabilität (nicht direkt als Information, wie in der IRT üblich) in Abhängigkeit der Personenfähigkeit geplotted, was ein typisches Muster ergibt: im mittleren Bereich wird die höchste Messgenauigkeit erreicht, an den Rändern sinkt sie etwas.
Grundsätzlich messen wir aber im gesamten Fähigkeitsbereich gut.
Die untere Graphik gibt uns Aufschluss darüber, in welchem Bereich die modellbasierten Fähigkeitsschätzungen liegen: der Großteil liegt zwischen -3 und 3 (was eine Folge dessen ist, wie das statistische Modell arbeitet) und wir erreichen grundsätzlich eine Normalverteilung (was so gesehen aber auch "vorne" schon als Annahme ins Modell gesteckt wurde).

```{r}
# thetgm1 <- fscores(gmodel1, full.scores.SE = TRUE, method = "EAP")
plot(density(thetgm1[,"F1"]), main = "Verteilung der 'protestantischen Arbeitsethik'-Dimension")
```


## Kurzzusammenfassung
Bisher lief alles schön glatt. 
Der Modellfit ist in Ordnung, die Reliabilität ist in Ordnung - wir haben einen Test, der eine schöne einzelne Dimension protestantischer Überzeugung von und Einstellung zu Arbeit erfassbar macht.
Aber mehr auch nicht! 
Spannend wäre jetzt zu untersuchen, inwiefern die psychologische Dimension, die wir gefunden haben, mit anderen Dimensionen zusammenhängt und letztlich noch viel mehr, ob sie auch mit anderen Ereignissen als der Beantwortung irgendwelcher Fragebögen zusammenhängt.
Ob also beispielsweise Personen, die einen hohen Wert auf der PWES erreichen, im echten Leben erfolgreich sind, viel arbeiten und ihre Freizeit zurückstellen im Geiste eines neu-protestantischen "work hard, play hardly" etc.
Oder im Sinne der eingehend geäußerten Kritik, ob solche eher konservativen Einstellungen im modernen Arbeitsleben vielleicht sogar kontrakproduktiv sind - außer bei Beamten, wo dann das Gegenteil der Fall ist.
Leider sind uns solche Untersuchungen vergönnt, da wir hierzu keine Daten haben (ob das schon andere untersucht haben, kann der übermütige Leser gerne nachschauen und mir oder der Allgemeinheit mitteilen).
Eine Minivalidierung der PWES können wir dennoch in Angriff nehmen - aber erst in einem hiermit angeteaserten späteren Post.


