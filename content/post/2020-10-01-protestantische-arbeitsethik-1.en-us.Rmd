---
title: Protestantische Arbeitsethik 1
author: Simon Buettner
date: '2020-09-01'
slug: protestantische-arbeitsethik-1.en-us
categories: []
tags: []
keywords:
  - tech
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
library(psych)
library(lavaan)
library(mirt)
library(dplyr)
load("../../static/data/ProtestandWorkEthic/PWES.Rdata")
```
# Was funktioniert Testentwicklung?
Mein erster Post soll Einblick darin geben, wie Psychologen grundsätzlich versucht, bestimmte psychologische Konstrukte/Eigenschaften, die er sich ausgedacht hat, empirisch zu untersuchen. 
Den eigentlich sehr spannenden Prozess der Itemgenerierung lassen wir hier außen vor und steigen bei der empirischen Überprüfung der Items ein.
**Was sind Items? Items sind die einzelnen Aufgaben, die man in einem Test bearbeitet.**
Bei Persönlichkeitstests sind es Aussagen wie "Ich lese gerne Blogs", die man z.B. von 1-5 danach bewerten soll, inwiefern man ihnen zustimmt.
Bei solchen Einschätzungen von 1-5 spricht man dann von Likert-Skalen bzw. einem Likert-Skalen Item.
Bei Leistungstests wäre ein Item z.B. eine Rechenaufgabe im offenen oder Multiple-Choice Format.

Den empirischen Teil der Fragebogenkonstruktion möchte ich dabei anhand der etwas ungewöhnlichen ["Protestant Work Ethic Scale"](https://psycnet.apa.org/record/1971-09987-001) bestehend aus 19 Likert-Skalen Items untersuchen.
Die dazugehörigen Daten sind auf [Open Psychometrics](https://openpsychometrics.org/_rawdata/) frei abrufbar. 
Wieso ausgerechnet so eine Randerscheinung psychologischer Konstrukte?
Mein Interesse rührt daher, dass nach Maßen der allgemeinen Intelligenz von Testseite her vor allem die Persönlichkeitskonstrukte [Integrität und Gewissenhaftigkeit Prädiktoren des Berufserfolgs](https://d1wqtxts1xzle7.cloudfront.net/44029822/Schmidt_and_Hunter_1998_Validity_and_Utility_of_Selection_Methods.pdf?1458742080=&response-content-disposition=inline%3B+filename%3DThe_Validity_and_Utility_of_Selection_Me.pdf&Expires=1601204492&Signature=APF0Po8QwU4hvdqoq6BGZ~5yrccNSPzkOxQtsuPV9VUXLa975b1rKCH0pbjUS-wPLsTXNBHOqpJh2nqcw61bkgqqHjxrAfOLQCEzhCxNr~U1Z9URk-cTdrx~UK3SbOxLyJuoN8~oz7eBkNSnbwjUAwYtp12zazFBQovcJZ2gtNfEFpxw1LcySHYIEaXi5Fmirq2WGcjPJ~P29j3bzfh7~aBVpUT7ddIeV6VxkrM5eUDMcAHJsY35UqPKxQT1v~uFIrzAcMs8DnZiq9OcjIkWBJ8~2dA2rdhWQQFbsgrUmhZwcVhsnEOhLbPG3236aGGiBHtGvuBzVanCHeGQQZPXEw__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA) sind.
Grundsätzlich würde ich nach Sichtung der Items der PWES das damit erfasste Konstrukt in der Nähe von Gewissenhaftigkeit und Integrität ansiedeln.
Erstaunlich fand ich eigentlich immer, dass diese Konstrukte klassischer (Sekundär-)Tugenden so bedeutsam sind, haben diese heutzutage doch irgendwie an Ansehen verloren - werden im schlimmsten Fall sogar auch in die Nähe der "autoritären Persönlichkeit" gestellt werden, wodurch sie beinahe etwas Schmuddeliges an sich hängen haben.
Gleichzeitig möchte ich gar nicht bestreiten, dass die Bedeutsamkeit dieser klassischen Tugenden auf mittlerweile doch recht alter Forschung basiert und heute ggf. an Gültigkeit nicht verloren hat.
Und dennoch: Auch bei agiler Arbeit dürfte am Ende wichtig sein, was bei dieser Arbeit rauskommt. 
Fleiß, Gewissenhaftigkeit und ein grundsätzliches Maß an Ehrlichkeit werden deshalb auch weiterhin bedeutsam sein.


In Deutschland haben diese Eigenschaften und das Verhältnis zu ihnen eine gewisse Sonderstellung, da es sich vor allem um "preußische Tugenden" (Pünktlichkeit, Arbeitsamkeit, Pflichtbewusstsein, Fleiß) handelt.
Heutzutage rühmt man sich besonders hier im Ländle dieser Tugenden (im Besonderen der Sparsamkeit), was sich nicht nur aber auch über die religiöse Geschichte ein Stück weit erklären lassen könnte: In Preußen wie in Schwaben (sind und) waren große Teile der Bevölkerung Protestanten. 
Diese Verwandtschaft findet schönen Ausdruck in den historischen Begebenheiten, dass der Schwabe Hegel im preußischen Berlin lehrte oder dass die "schwäbischen" Hohenzollern die preußischen Könige stellten.


Ich hatte mich deswegen während des Studiums schon gefragt, wieso noch niemand auf die Idee gekommen ist, eine Art "Schwäbische Hausfrauenskala" oder etwas leichter von der Zunge gehenden "Ländleskala" zu entwickeln. 
Solange sich niemand dieses Unternehmens annimmt, muss eben auf die "Protestant Work Ethic Scale" (PWES) zurückgegriffen werden.
Diese Skala geht zurück auf Max Webers Werk "Die protestantische Ethik und der Geist des Kapitalismus", in dem Weber die These verfolgt, der asketisch angelegte in Nordeuropa und mit Nordeuropa assoziierte Kulturkreise verbreitete Protestantismus (im Besonderen der Calvinismus) sei als eine Triebkraft hinter der Entstehung des (Geist des) Kapitalismus zu verstehen.

## Wie sehen die PWES Items aus?
548 Personen (vornehmlich aus den USA) haben Einschätzungen auf Likert-Skalen von 1-5 darüber gegeben, inwiefern sie folgenden Aussagen/Items zustimmen:


* Q1	Most people spend too much time in unprofitable amusements. 
* Q2	Our society would have fewer problems if people had less leisure time. 
* Q3	Money acquired easily (e.g. through gambling or speculation) is usually spent unwisely. 
* Q4	There are few satisfactions equal to the realization that one has done one's best at a job. 
* Q5	The most difficult college courses usually turn out to be the most rewarding. 
* Q6	Most people who don’t succeed in life are just plain lazy. 
* [Q7	The self-made person is likely to be more ethical than someone who is born to wealth.]
* Q8	I often feel I would be more successful if I sacrificed certain pleasures. 
* Q9__Rekodiert	People should have more leisure time to spend in relaxation.  
* Q10	Anyone who is able and willing to work hard has a good chance of succeeding. 
* Q11	People who fail at a job have usually not tried hard enough. 
* Q12	Life would have very little meaning if we never had to suffer. 
* Q13__Rekodiert	Hard work offers little guarantee of success. 
* [Q14	The credit card is a ticket to careless spending.]
* Q15__Rekodiert	Life would be more meaningful if we had more leisure time. 
* Q16	The person who can approach an unpleasant task with enthusiasm is the one who gets ahead. 
* Q17	If one works hard enough they are likely to make a good life for themselves. 
* Q18	I feel uneasy when there is little work for me to do. 
* Q19	A distaste for hard work usually reflects a weakness of character.

Wie man sieht, verkörpert diese Skala unsere (Groß-)Eltern, die erhobenen Zeigefinders mahnen, unsere Zeit nicht zu verschwenden, mehr Geld zu sparen, und stets hart zu arbeiten, denn darauf kommt es an, das lohnt sich.
Außerdem kann man erkennen, dass jeglicher Bezug zur für den Calvinismus bedeutsamen Prädestinationslehre fehlt.
Ein solcher Bezug wäre sicher unheimlich spannend, denn psychologisch kann der calvinistische Glaube an Prädestination mit interessanten Effekten einhergehen.
Zum einen sucht man als Gläubiger durch weltlichen Erfolg zu bestätigen, dass man von Gott auserwählt ist und zum anderen kann der Glaube, auserwählt zu sein, ungeheuerlich das Selbstvertrauen steigern. 
Nicht zu unrecht konzentriert sich Weber deshalb auf den Calvinismus. 
Interessant wäre die Wirkung von Prädestinationsüberzeugungen deshalb alle Mal, auch wenn diese gar nicht in der Skala aufgenommen wurden, was aber auch verständlich ist, ist die Skala doch eine "Arbeitsethik"-Skala.

# Grundlegende Faktorenstruktur: fa.parallel()
G'nug g'schwätzt.
**Um die Frage zu beantworten, welche Faktorstruktur der PWES zugrunde liegt, ist für den gewieften Psychologen zunächst zu klären, wie viele Faktoren/Dimensionen sich hinter den Daten verbergen. Aber was bedeutet das?** 
Wenn Psychologen einen Test konstruieren, untersuchen sie in der Regel, inwiefern einzelne Items des Tests miteinander zusammenhängen bzw. auch nicht miteinander zusammenhängen. 
Bei uns: Stimmen jene, die der Aussage "Wenn man hart genug arbeitet, wird das eigene Leben mit höherer Wahrscheinlichkeit besser" (Q17) zustimmen, auch der Aussage zu "Jeder der fähig und willens ist, hart zu arbeiten, hat eine gute Chance erfolgreich zu sein" (Q10).
Und wenn ja, welchen Aussagen stimmen sie dann noch zu? Welche Aussagen werden unabhängig eines solchen Bündels an Aussagen beantwortet?
Ziel ist dann, aus den einzelnen Antworten eine aggregierte Information zu machen. 
Also statt zu sagen, Person A stimmt Items 1, 2, 3 etc. zu, zu sagen Person A ist davon überzeugt, dass harte Arbeit zu Erfolg führt.


Auf diese Weise wird eine (statistische) Dimension / ein Faktor dann zu einem psychologischen Konstrukt, einer Persönlichkeitseigenschaft oder -fähigkeit oder einem latenten Trait - um nur einige Benennungen aufzuführen.
Diese übergeordneten Eigenschaften mit einem Test zu erfassen, ist das Ziel der (meisten) Testentwickler. 
Wichtig ist dabei, dass die einzelnen Items hoch mit dieser statistisch konstruierten Dimension zusammenhängen (und im einfachsten Fall sehr wenig mit anderen Dimensionen), man sagt "hoch auf der Dimension laden", da es sich um Faktorladungen handelt.
Da das mit den Items Q7 und Q14 nicht recht geklappt hat, sind diese rausgeflogen.
Hat man dann eine Zuordnung von Items zu den Dimensionen gefunden, berechnet man in irgendeiner Weise (zumeist ein einfacher Summenscore über die Items hinweg) auf Basis genau dieser Items z.B. inwiefern eine Person der Überzeugung ist, dass harte Arbeit erfolgreich macht.

Zur Untersuchung der Faktorstruktur bedient man sich (im Zweifel über Umwege) vergleichsweise einfacher linearer Algebra, um die Struktur hinter den gegebenen Antworten auf die vielen Items zu untersuchen.
**Über eine Hauptkomponenten- oder Faktorenanalyse kann man wie beschrieben Dimensionen aus ganz vielen verschiedenen gegebenen Antworten extrahieren.**
Das sind keine psychologiespezifische Methoden, sondern vergleichsweise weit verbreitete Methoden.
So findet zum Beispiel die Hauptkomponentenanalyse auch im Machine Learning Einsatz, ebenfalls um aus vielen gegebenen Daten die wirklich vorhandene Struktur zu extrahieren, einen Datenwust also grundsätzlich zu vereinfachen.

Das erste Problem besteht dann darin, zu entscheiden, wie viel Struktur tatsächlich hinter den Daten steht, also wie viele Dimensionen wir finden können.
Klassischerweise wird hierfür ein Screeplot genutzt, der die Eigenwerte extrahierter Hauptkomponenten/Faktoren - das sind quasi die übergeordneten Dimensionen, die wir suchen - danach sortiert, wie viel Rauschen bzw. Varianz in den Daten sie erklären.
Außerdem werden mit der hier verwendet 'fa.parallel' Funktion zufällig Daten simuliert, die unseren Daten ähneln, aber keine der dahinterliegenden Struktur enthalten. 
Auf diese Weise können wir dann entscheiden, was echte Struktur in den Daten ist und was nur zufälliges Rauschen ist.
Man sieht nun sehr schön, dass besonders ein Faktor / eine Hauptkomponente / Dimension in den Daten steckt.
Allerdings ließen sich auch weitere Dimensionen finden, die nicht rein zufälliger Natur zu sein scheinen (vornehmlich anhand der Punkte über der unteren roten Linie zu sehen, oder am Output "Parallel analysis suggests that the number of factors =  4") - doch wie man damit umgeht, wird dann vielleicht einmal ein eigener Blogpost.
Wir halten ganz im Sinne des Tests die Sparsamkeit hoch und betrachten nur diese eine Hauptdimension.


```{r}
set.seed(1234)
fa.parallel(dat)
```

# Das Graded Response Model der protestantischen Arbeitsethik: Model Fit
Um den Test jetzt genauer statistisch zu untersuchen, stülpen wir den Daten ein eindimensionales statistisches Modell über (was genau das macht sei hier zurückgestellt. Eine Google Suche ergibt diese netten Seiten: [allgemeine Erklärung](https://www.statisticshowto.com/graded-response-model-ordered-categorical/) sowie [eine detailliertere Erklärung](http://statmath.wu-wien.ac.at/~hatz/psychometrics/11w/GPCM_GRM_GRASOM.pdf)). 
Ganz einfach gesagt modellieren wir, wie die Items beantwortet werden in Abhängigkeit der zugrundeliegenden Fähigkeitsausprägung, also unserer sparsam gewählten Hauptdimension.
Damit gehen wir etwas über eine normale Faktorenanalyse hinaus, erreichen aber ein sehr ähnliches (aber besseres) Ziel wie mit dieser.

```{r}
# gmodel1 <- mirt(dat, 1, "graded", TOL = .0001)
summary(gmodel1)
# (m2.gmodel1<-M2(gmodel1, type = "C2"))
m2.gmodel1 %>% round(.,3)
itemfit(gmodel1, fit_stats = "PV_Q1")
```
Über die hier verwendeten Funktionen können wir schon einige Aussagen treffen:

  1. Die "summary"-Funktion zeigt uns: eindimensionales Modell erklärt immerhin 41% der Varianz in den Daten: "Proportion Var:  0.411")
  
  2. Die "summary"-Funktion zeigt weiter: alle Items laden hinreichend gut auf diesem Faktor: die Zahlen unter F1 geben die Faktorladungen an ( = wie sehr hängt die Zustimmung  zu einem Item von der zugrundeliegenden Eigenschaft ab) sind mindestens bei .44 - ab .32 ist es "gut genug".
  
  3. "M2" gibt uns einige CFA Fit Indizes, das sind Kennwerte, die uns erlauben einzuschätzen, wie gut unser insgesamt Modell auf die Testdaten passt (oder andersherum). Dabei zeigt sich: Modell und Daten passen relativ gut aufeinander (RMSEA halbwegs nahe 0.05, SRMSR deutlich kleiner .1, TLI/CFI über .9). Aber, aber: wir haben ja auch schon 2 Items ausgeschlossen. Und dennoch Raum nach oben ist auch hier noch.
  
  4. "itemfit" zeigt uns, inwiefern die empirischen Antworten auf einzelne Items *nicht* modellkonform sind - quasi eine Betrachtung wie bei M2 aber auf Item- statt auf Testebene. Wünschenswert ist, dass "p.PV_Q1" größer als .05 oder .01 ist, dass also keine signifikante Modellabweichung bei einzelnen Items besteht. Mit Ausnahme von Q9A ist das grundsätzlich der Fall.

# Messgenauigkeit
Jetzt gehen wir einmal in Richtung Benutzbarkeit der Skala.
Wir schauen uns hierfür die Reliabilität der Skala an und außerdem die Verteilung der (latenten) Theta-Werte an, also die PWES Dimension, die wir konstruiert haben.
**Die Reliabilität gibt an, wie genau wir messen können, welche Ausprägung eine Person auf einer psychologischen Dimension erreicht.**
Unsere psychologischen Messungen werden immer mit einer gewissen Ungenauigkeit behaftet sein.
Um aber valide Aussagen darüber zu treffen, ob eine Person sehr gewissenhaft ist oder nicht sowie um zu entscheiden, ob Person A gewissenhafter als Person B ist, sollte unsere Einschätzung über einer Einschätzung mittels Würfelwurfs liegen.
Die Reliabilität kann zwischen 0 (keine Messgenauigkeit, Würfelwurf) und 1 liegen (perfekte Messgenauigkeit).
Ab .7 ist die Genauigkeit grundsätzlich in Ordnung, bei .8 werden wir langsam glücklich und (viel) mehr als .9 sollten wir nicht erwarten.

Innerhalb der (Item-Response-Theory)[https://en.wikipedia.org/wiki/Item_response_theory] (IRT; vereinfacht: eine psychologische Testtheorie) gibt es nun eigentlich keinen solchen natürlichen Wert, um die Messgenauigkeit eines Tests unabhängig der Personenfähigkeit anzugeben. 
Stattdessen liefert jedes einzelne Item für unterschiedliche Personenfähigkeiten unterschiedlich viel Information (hierbei können wir die statistische [Fischer-]Information relativ unproblematisch als alltagssprachliche Information auffassen).
Manche Items helfen uns also sehr gut im oberen Bereich zu differenzieren, umgekehrt aber im unteren Bereich nicht so sehr; oder auch anders herum. 

Grundsätzlich ist diese Auffassung der Messgenauigkeit sehr intuitiv. 
Wir stellen uns vor, wir möchten die Mathematikfähigkeit von Abiturienten in Erfahrung bringen.
Dazu stellen wir ihnen die Frage "Was ergibt 2+2?". 
Wahrscheinlich (und hoffentlich) wird jeder diese Frage korrekt beantworten, denn sie ist viel zu einfach für diese Zielgruppe.
Wir haben dann keine Grundlage um einem Schüler zu attestieren, er sei mehr oder weniger mathebegabt als ein anderer.
Die Beantwortung von 2+2 liefert uns also keine Information, denn jeder kann sie richtig beantworten, in einem Test zur Erfassung der Mathefähigkeit von Abiturienten wäre diese Frage also Fehl am Platz.
Schön ist nun, dass diese plausible Betrachtungsweise innerhalb der IRT ebenfalls gilt.
Unschön ist, dass man nicht direkt einen Wert anschauen kann, um die Messgenauigkeit eines Tests zu beurteilen.
Aber es gibt auch innerhalb der IRT Abhilfe, indem man sich die marginale (oder empirische) Reliabilität anschaut, die man "ganz normal" wie andere Reliabilitäten interpretieren kann ([hier gut erklärt](https://stats.stackexchange.com/questions/427631/difference-between-empirical-and-marginal-reliability-of-an-irt-model), sogar im Kontext des R Pakets 'mirt', das ich hauptsächlich verwende. 
Grundsätzlich wird die Messgenauigkeit an den einzelnen Fähigkeitsausprägungen ins Verhältnis gesetzt zur allgemeinen Streuung der Fähigkeit - das entspricht der Definition der Messgenauigkeit nach klassischer Testtheorie).

```{r}
marginal_rxx(gmodel1)
plot(gmodel1, type = "rxx", theta_lim = c(-3,3) )
```

Die marginale Reliabilität liegt bei .9 (Output von "marginal_rxx"), ist also ziemlich zufriedenstellend.
Außerdem habe ich die Messgenauigkeit als Reliabilität (nicht direkt als Information, wie in der IRT üblich) in Abhängigkeit der Personenfähigkeit geplotted, was ein typisches Muster ergibt: im mittleren Bereich wird die höchste Messgenauigkeit erreicht, an den Rändern sinkt sie etwas.
Grundsätzlich messen wir aber im gesamten Fähigkeitsbereich gut.
Die untere Graphik gibt uns Aufschluss darüber, in welchem Bereich die modellbasierten Fähigkeitsschätzungen liegen - der Großteil liegt zwischen -3 und 3 (was eine Folge dessen ist, wie das statistische Modell arbeitet) und wir erreichen grundsätzlich eine Normalverteilung (was so gesehen aber auch "vorne" schon als Annahme ins Modell gesteckt wurde).

```{r}
# thetgm1 <- fscores(gmodel1, full.scores.SE = TRUE, method = "EAP")
plot(density(thetgm1[,"F1"]), main = "Verteilung der 'protestantischen Arbeitsethik'-Dimension")
```


# Kurzzusammenfassung
Bisher lief alles schön glatt. 
Der Modellfit ist in Ordnung, die Reliabilität ist in Ordnung - wir haben einen Test, der schöne einzelne Dimension protestantischer Arbeitsethik erfassbar macht.
Aber mehr leider auch nicht! 
Spannend wäre jetzt zu untersuchen, inwiefern die psychologische Dimension, die wir gefunden haben mit anderen Dimensionen zusammenhängt und letztlich noch viel mehr, ob sie auch mit anderen Ereignissen als der Beantwortung irgendwelcher Fragebögen einhergeht.
Ob also beispielsweise Personen, die einen hohen Wert auf der PWES haben im echten Leben erfolgreich sind, viel arbeiten und ihre Freizeit zurückstellen (work hard, play hardly) etc.
Leider ist uns die Untersuchung des Letzteren vergönnt, da wir hierzu keine Daten haben.
Eine Minivalidierung der PWES können wir dennoch in Angriff nehmen - aber erst in einem späteren Post.